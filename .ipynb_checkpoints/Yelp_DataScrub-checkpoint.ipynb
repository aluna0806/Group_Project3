{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract JSONs into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Establish paths to JSON files\n",
    "biz = \"Data/yelp_academic_dataset_business.json\"\n",
    "reviews = \"Data/yelp_academic_dataset_review.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Business data into Pandas\n",
    "biz_df = pd.read_json(biz, lines=True)\n",
    "\n",
    "#biz_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review & Scrub Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id      object\n",
       "name             object\n",
       "address          object\n",
       "city             object\n",
       "state            object\n",
       "postal_code      object\n",
       "latitude        float64\n",
       "longitude       float64\n",
       "stars           float64\n",
       "review_count      int64\n",
       "is_open           int64\n",
       "attributes       object\n",
       "categories       object\n",
       "hours            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assess Data TYpes\n",
    "biz_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Las Vegas     31631\n",
       "Toronto       20366\n",
       "Phoenix       20171\n",
       "Charlotte     10422\n",
       "Scottsdale     9342\n",
       "Name: city, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assess what cities to pull in: Las Vegas, Toronto, Phoenix, Charlotte. Not including Scottsdale as it's close to Phoenix\n",
    "biz_df['city'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove closed businesses, column is_open\n",
    "OpenBiz = biz_df[biz_df['is_open']==1]\n",
    "\n",
    "#OpenBiz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    168903\n",
       "Name: is_open, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if \"0\" were removed\n",
    "OpenBiz['is_open'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop \"is_open\" as it is no longer needed\n",
    "biz_df2 = OpenBiz.drop('is_open', axis=1)\n",
    "\n",
    "#biz_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split categories (strings) in to their own row\n",
    "Categories = biz_df2.assign(categories = biz_df2.categories.str.split(',')).explode('categories')\n",
    "\n",
    "#Categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Restaurants      30776\n",
       " Shopping         21555\n",
       " Food             18475\n",
       " Home Services    14886\n",
       "Restaurants       13189\n",
       "Name: categories, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Why are there two different \"Restaurant\" categories????\n",
    "\n",
    "Categories.categories.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Restaurants           30776\n",
       "Restaurants            13189\n",
       " Pop-Up Restaurants       12\n",
       "Pop-Up Restaurants         4\n",
       "Name: categories, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Categories[Categories['categories'].str.contains('Restaurants', case=True, na=False)].categories.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update \"Restaurants\"(2) to uniquely be \"Restaurant\" as the category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all items that are not \"Restaurant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read Review data into Pandas\n",
    "#review_df = pd.read_json(reviews)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Player DataFrames\n",
    "* Reduce Player DFs to only the 9 columns we want to evaluate\n",
    "* Update column headers to coorespond with schema \n",
    "* Add 'Season' column to DataFrames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018 Player Data reduction\n",
    "# Extract \"Player\", \"Tm\", \"Pos\", \"G\", \"FG\", \"FG%\", \"FT\", \"FT%\" and \"PTS\"\n",
    "reduced_player18_df = player_2018_df.loc[:, [\"Player\", \"Tm\", \"Pos\", \"G\", \"FG\", \"FG%\", \"FT\", \"FT%\", \"PTS\"]]\n",
    "reduced_player18_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019 Player Data reduction\n",
    "# Extract \"Player\", \"Tm\", \"Pos\", \"G\", \"FG\", \"FG%\", \"FT\", \"FT%\" and \"PTS\"\n",
    "reduced_player19_df = player_2019_df.loc[:, [\"Player\", \"Tm\", \"Pos\", \"G\", \"FG\", \"FG%\", \"FT\", \"FT%\", \"PTS\"]]\n",
    "reduced_player19_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Header updates, Player Data:\n",
    "revised_player18_df = reduced_player18_df.rename(columns={'Tm': 'team_name', 'Pos': 'Position',\t'G': 'Games', 'FG%': 'FG_pct', 'FT%': 'FT_pct', 'PTS': 'Total_Pts'})\n",
    "\n",
    "revised_player19_df = reduced_player19_df.rename(columns={'Tm': 'team_name', 'Pos': 'Position',\t'G': 'Games', 'FG%': 'FG_pct', 'FT%': 'FT_pct', 'PTS': 'Total_Pts', })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'Season' column\n",
    "revised_player18_df.insert(0, \"Season\", 2018, True)\n",
    "\n",
    "revised_player19_df.insert(0, \"Season\", 2019, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Game DataFrames\n",
    "* Remove the Box Score column from the Game Data\n",
    "* Update the Game Data DFs so team names match the 3 letter accrynyms on the Player Data DFs\n",
    "* Update column headers to coorespond with schema \n",
    "* Add 'Season' column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018 Game Data reduction\n",
    "# Extract \"Date\", \"Visitor/Neutral\", \"PTS\", \"Visitor/Neutral\", \"PTS.1\"\n",
    "reduced_game18_df = wnba_2018_df.loc[:, [\"Date\", \"Visitor/Neutral\", \"PTS\", \"Home/Neutral\", \"PTS.1\"]]\n",
    "reduced_game18_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019 Game Data reduction\n",
    "# Extract \"Date\", \"Visitor/Neutral\", \"PTS\", \"Visitor/Neutral\", \"PTS.1\"\n",
    "reduced_game19_df = wnba_2019_df.loc[:, [\"Date\", \"Visitor/Neutral\", \"PTS\", \"Home/Neutral\", \"PTS.1\"]]\n",
    "reduced_game19_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace each full team name with 3-letter accrynym (i.e. DallasWings --> DAL)\n",
    "\n",
    "replacements = {\n",
    "    \"Dallas Wings\": \"DAL\",\n",
    "    \"Chicago Sky\": \"CHI\",\n",
    "    \"New York Liberty\": \"NYL\",\n",
    "    \"Las Vegas Aces\": \"LVA\",\n",
    "    \"Atlanta Dream\": \"ATL\",\n",
    "    \"Los Angeles Sparks\": \"LAS\",\n",
    "    \"Phoenix Mercury\": \"PHO\",\n",
    "    \"Seattle Storm\": \"SEA\",\n",
    "    \"Indiana Fever\": \"IND\",\n",
    "    \"Washington Mystics\": \"WAS\",\n",
    "    \"Minnesota Lynx\": \"MIN\",\n",
    "    \"Connecticut Sun\": \"CON\",\n",
    "}\n",
    "reduced_game18_df[\"Visitor/Neutral\"].replace(replacements, inplace=True)\n",
    "\n",
    "reduced_game18_df[\"Home/Neutral\"].replace(replacements, inplace=True)\n",
    "\n",
    "reduced_game19_df[\"Visitor/Neutral\"].replace(replacements, inplace=True)\n",
    "\n",
    "reduced_game19_df[\"Home/Neutral\"].replace(replacements, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers updates, Game Data:\n",
    "revised_game18_df = reduced_game18_df.rename(columns={'Visitor/Neutral': 'away_team', 'PTS': 'away_team_pts', 'Home/Neutral': 'home_team', 'PTS.1': 'home_team_pts'})\n",
    "\n",
    "revised_game19_df = reduced_game19_df.rename(columns={'Visitor/Neutral': 'away_team', 'PTS': 'away_team_pts', 'Home/Neutral': 'home_team', 'PTS.1': 'home_team_pts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'Season' Column to Game Data\n",
    "revised_game18_df.insert(0, \"Season\", 2018, True)\n",
    "\n",
    "revised_game19_df.insert(0, \"Season\", 2019, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to local database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = \"postgres:postgres@localhost:5432/WNBA\"\n",
    "engine = create_engine(f'postgresql://{connection_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm tables\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DataFrames into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_game18_df.to_sql(name='Game_Data_18', con=engine, if_exists='append', index=True)\n",
    "\n",
    "revised_game19_df.to_sql(name='Game_Data_19', con=engine, if_exists='append', index=True)\n",
    "\n",
    "revised_player18_df.to_sql(name='Player_Data_18', con=engine, if_exists='append', index=True)\n",
    "\n",
    "revised_player19_df.to_sql(name='Player_Data_19', con=engine, if_exists='append', index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
